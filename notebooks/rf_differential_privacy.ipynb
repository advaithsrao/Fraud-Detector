{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /common/home/ps1279/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from detector.data_loader import LoadEnronData, LoadPhishingData, LoadSocEnggData\n",
    "from detector.labeler import EnronLabeler, MismatchLabeler\n",
    "from ethics.differential_privacy import RandomForestPrivacyModel\n",
    "from detector.preprocessor import Preprocessor\n",
    "from utils.util_modeler import evaluate_and_log, get_f1_score, Augmentor\n",
    "\n",
    "import wandb\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init wandb for model tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/05/2023 23:39:06:ERROR:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madvaithrao\u001b[0m (\u001b[33mregressors\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /common/home/ps1279/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/common/home/ps1279/Fraud-Detector/wandb/run-20231205_233909-rptqmnfr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/regressors/Fraud-Detector/runs/rptqmnfr' target=\"_blank\">iconic-breeze-112</a></strong> to <a href='https://wandb.ai/regressors/Fraud-Detector' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/regressors/Fraud-Detector' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/regressors/Fraud-Detector/runs/rptqmnfr' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector/runs/rptqmnfr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbdict = {\n",
    "    'key': os.getenv('WANDB_API_KEY'),\n",
    "    'entity': os.getenv('WANDB_ENTITY'),\n",
    "    'project': os.getenv('WANDB_PROJECT'),\n",
    "}\n",
    "wandb.login(key=wandbdict['key'])\n",
    "run = wandb.init(project=wandbdict['project'], entity=wandbdict['entity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/fraud_detector_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data.Split == 'Train']\n",
    "sanity_data = data[data.Split == 'Sanity']\n",
    "gold_fraud_data = data[data.Split == 'Gold Fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'num_labels': 2,\n",
    "    'n_estimators': 100,\n",
    "    'criterion': 'gini'\n",
    "}\n",
    "\n",
    "model = RandomForestPrivacyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lnh081ou) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f74cfedf89a4095aee568bfa7cbcfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.022 MB of 0.022 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sky-109</strong> at: <a href='https://wandb.ai/regressors/Fraud-Detector/runs/lnh081ou' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector/runs/lnh081ou</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231205_214822-lnh081ou/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:lnh081ou). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d6313528d041969c9df9845b906388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112813154856365, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/common/home/ps1279/Fraud-Detector/wandb/run-20231205_215125-4jzx14ww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/regressors/Fraud-Detector/runs/4jzx14ww' target=\"_blank\">generous-energy-110</a></strong> to <a href='https://wandb.ai/regressors/Fraud-Detector' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/regressors/Fraud-Detector' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/regressors/Fraud-Detector/runs/4jzx14ww' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector/runs/4jzx14ww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run = wandb.init(config=hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentor = Augmentor()\n",
    "\n",
    "train_body, train_labels = augmentor(\n",
    "    train_data['Body'].tolist(),\n",
    "    train_data['Label'].tolist(),\n",
    "    aug_label=1,\n",
    "    num_aug_per_label_1=9,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data = pd.DataFrame(\n",
    "    {\n",
    "        'Body': train_body,\n",
    "        'Label': train_labels\n",
    "    }\n",
    ")\n",
    "\n",
    "train_data.drop_duplicates(subset=['Body'], inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('./data/augmented_train_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/augmented_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertModel\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mlflow.sklearn import save_model\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from ethics.base import BaseDistilbertModel\n",
    "from utils.util_modeler import Word2VecEmbedder, TPSampler, get_f1_score\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "from diffprivlib.models.forest import RandomForestClassifier\n",
    "\n",
    "\n",
    "class RandomForestPrivacyModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_labels: int = 2,\n",
    "        n_estimators = 100,\n",
    "        criterion = 'gini',\n",
    "        njobs = -1\n",
    "    ):\n",
    "        self.num_labels = num_labels\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.njobs = njobs\n",
    "\n",
    "        self.vectorizer = Word2VecEmbedder()\n",
    "        \n",
    "        self.model = Pipeline([\n",
    "            ('vectorizer', self.vectorizer),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=self.n_estimators, criterion=self.criterion, n_jobs=self.njobs))\n",
    "        ])\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        body: pd.Series | list[str],\n",
    "        label: pd.Series | list[int],\n",
    "        wandb: wandb = None,\n",
    "    ):\n",
    "        \"\"\"Trains the SVM model.\n",
    "\n",
    "        Args:\n",
    "            body (pd.Series | list[str]): The body of the email.\n",
    "            label (pd.Series | list[int]): The label of the email.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the body and label are not of the same size.\n",
    "        \"\"\"\n",
    "        if isinstance(body, pd.Series):\n",
    "            body = body.tolist()\n",
    "        if isinstance(label, pd.Series):\n",
    "            label = label.tolist()\n",
    "\n",
    "        body_train, body_val, label_train, label_val = train_test_split(body, label, test_size=0.2, random_state=42, stratify=label)\n",
    "\n",
    "        # Train the RF model\n",
    "        epsilons = [1e-8, 1e-2, 1, 7.5, 20]\n",
    "        accuracies = []\n",
    "\n",
    "        for eps in epsilons:\n",
    "            self.model.named_steps['classifier'] = RandomForestClassifier(n_estimators=self.n_estimators, criterion=self.criterion, n_jobs=self.njobs, epsilon=eps)\n",
    "            # self.model.set_params(classifier__epsilon=eps)\n",
    "            self.model.fit(body_train, label_train)\n",
    "\n",
    "            accuracy = get_f1_score(label_val, self.model.predict(body_val), average = 'macro')\n",
    "            print('********* \\n Epsilon %.2f - Validation F1 Score %.5f \\n *********' % (eps, accuracy))\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        plt.plot(epsilons, accuracies, marker='o')\n",
    "        plt.xscale('log')  # Use a logarithmic scale for better visibility\n",
    "        plt.xlabel('Epsilon')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.title('F1 Score vs Epsilon')\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.savefig(\"rf_dp_accuracy_vs_epsilon_plot.png\")\n",
    "\n",
    "        # Log the plot to wandb\n",
    "        wandb.log({\"Accuracy vs Epsilon\": plt})\n",
    "        \n",
    "        print(f'{\"=\"*20} \\n Best Model for Epsilon = {epsilons[np.argmax(accuracies)]} with Validation F1 Score = {np.max(accuracies)} \\n {\"=\"*20}')\n",
    "        \n",
    "        #Fit model with best epsilon\n",
    "        self.model.named_steps['classifier'] = RandomForestClassifier(n_estimators=self.n_estimators, criterion=self.criterion, n_jobs=self.njobs, epsilon=epsilons[np.argmax(accuracies)])\n",
    "        \n",
    "        self.model.fit(body, label)\n",
    "\n",
    "        print(f'{\"=\"*20} Training Done {\"=\"*20}')\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        body: pd.Series | list[str],\n",
    "    ):\n",
    "        \"\"\"Predicts the labels of the given data.\n",
    "\n",
    "        Args:\n",
    "            body (pd.Series | list[str]): The body of the email.\n",
    "\n",
    "        Returns:\n",
    "            np.array: The predictions of the model.\n",
    "        \"\"\"\n",
    "        if isinstance(body, pd.Series):\n",
    "            body = body.tolist()\n",
    "\n",
    "        # Make predictions using the trained SVM model\n",
    "        predictions = self.model.predict(body)\n",
    "\n",
    "        if isinstance(predictions, np.ndarray):\n",
    "            predictions = predictions.tolist()\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def save_model(\n",
    "        self,\n",
    "        path: str,\n",
    "    ):\n",
    "        \"\"\"Saves the model to the given path.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to save the model to.\n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        save_model(self.model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestPrivacyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2VecEmbedder' object has no attribute 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/arao/Local/Github/Fraud-Detector/notebooks/rf_differential_privacy.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/arao/Local/Github/Fraud-Detector/notebooks/rf_differential_privacy.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Call your code that produces output\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/arao/Local/Github/Fraud-Detector/notebooks/rf_differential_privacy.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(train_data[\u001b[39m'\u001b[39;49m\u001b[39mBody\u001b[39;49m\u001b[39m'\u001b[39;49m], train_data[\u001b[39m'\u001b[39;49m\u001b[39mLabel\u001b[39;49m\u001b[39m'\u001b[39;49m], wandb \u001b[39m=\u001b[39;49m run)\n",
      "File \u001b[0;32m~/Fraud-Detector/ethics/differential_privacy.py:87\u001b[0m, in \u001b[0;36mRandomForestPrivacyModel.train\u001b[0;34m(self, body, label, wandb)\u001b[0m\n\u001b[1;32m     84\u001b[0m accuracies \u001b[39m=\u001b[39m []\n\u001b[1;32m     86\u001b[0m \u001b[39mfor\u001b[39;00m eps \u001b[39min\u001b[39;00m epsilons:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mset_params(classifier__epsilon\u001b[39m=\u001b[39;49meps)\n\u001b[1;32m     88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(body_train, label_train)\n\u001b[1;32m     90\u001b[0m     accuracy \u001b[39m=\u001b[39m get_f1_score(label_val, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(body_val), average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/sklearn/pipeline.py:222\u001b[0m, in \u001b[0;36mPipeline.set_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_params\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Set the parameters of this estimator.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \n\u001b[1;32m    206\u001b[0m \u001b[39m    Valid parameter keys can be listed with ``get_params()``. Note that\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39m        Pipeline class instance.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_params(\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/sklearn/utils/metaestimators.py:68\u001b[0m, in \u001b[0;36m_BaseComposition._set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replace_estimator(attr, name, params\u001b[39m.\u001b[39mpop(name))\n\u001b[1;32m     67\u001b[0m \u001b[39m# 3. Step parameters and other initialisation arguments\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mset_params(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m     69\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/sklearn/base.py:223\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m params:\n\u001b[1;32m    221\u001b[0m     \u001b[39m# Simple optimization to gain speed (inspect is slow)\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 223\u001b[0m valid_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    225\u001b[0m nested_params \u001b[39m=\u001b[39m defaultdict(\u001b[39mdict\u001b[39m)  \u001b[39m# grouped by prefix\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/sklearn/pipeline.py:201\u001b[0m, in \u001b[0;36mPipeline.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_params\u001b[39m(\u001b[39mself\u001b[39m, deep\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    185\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get parameters for this estimator.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[39m    Returns the parameters given in the constructor as well as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m        Parameter names mapped to their values.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_params(\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m, deep\u001b[39m=\u001b[39;49mdeep)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/sklearn/utils/metaestimators.py:46\u001b[0m, in \u001b[0;36m_BaseComposition._get_params\u001b[0;34m(self, attr, deep)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m name, estimator \u001b[39min\u001b[39;00m estimators:\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m estimator\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     47\u001b[0m             out[\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (name, key)] \u001b[39m=\u001b[39m value\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/sklearn/base.py:195\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    193\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    194\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names():\n\u001b[0;32m--> 195\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, key)\n\u001b[1;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mtype\u001b[39m):\n\u001b[1;32m    197\u001b[0m         deep_items \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mget_params()\u001b[39m.\u001b[39mitems()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2VecEmbedder' object has no attribute 'model_name'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Call your code that produces output\n",
    "model.train(train_data['Body'], train_data['Label'], wandb = run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {}\n",
    "os.makedirs('/common/home/ps1279/models/rf_diff_privacy/2023-12-05/rf_diff_privacy/logs', exist_ok=True)\n",
    "save_path='/common/home/ps1279/models/rf_diff_privacy/2023-12-05/rf_diff_privacy/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on all datasets and generate logs + mismatch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Prediction'] = model.predict(body=train_data['Body'])\n",
    "evaluate_and_log(x=train_data['Body'].tolist(), y_true=train_data['Label'].tolist(), y_pred=train_data['Prediction'].tolist(), filename=os.path.join(save_path,'logs/train.log'), experiment=run, id = train_data['Mail-ID'].tolist())\n",
    "f1_scores['train'] = get_f1_score(y_true=train_data['Label'].tolist(), y_pred=train_data['Prediction'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_data['Prediction'] = model.predict(body=sanity_data['Body'])\n",
    "evaluate_and_log(x=sanity_data['Body'].tolist(), y_true=sanity_data['Label'].tolist(), y_pred=sanity_data['Prediction'].tolist(), filename=os.path.join(save_path,'logs/sanity.log'), experiment=run, id = sanity_data['Mail-ID'].tolist())\n",
    "f1_scores['sanity'] = get_f1_score(y_true=sanity_data['Label'].tolist(), y_pred=sanity_data['Prediction'].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fraud_data['Prediction'] = model.predict(body=gold_fraud_data['Body'])\n",
    "evaluate_and_log(x=gold_fraud_data['Body'].tolist(), y_true=gold_fraud_data['Label'].tolist(), y_pred=gold_fraud_data['Prediction'].tolist(), filename=os.path.join(save_path,'logs/gold_fraud.log'), experiment=run, id = gold_fraud_data['Mail-ID'].tolist())\n",
    "f1_scores['gold_fraud'] = get_f1_score(y_true=gold_fraud_data['Label'].tolist(), y_pred=gold_fraud_data['Prediction'].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save mismatch data into a csv file\n",
    "mismatch_data = pd.concat(\n",
    "    [\n",
    "        train_data[train_data['Prediction'] != train_data['Label']],\n",
    "        sanity_data[sanity_data['Prediction'] != sanity_data['Label']],\n",
    "        gold_fraud_data[gold_fraud_data['Prediction'] != gold_fraud_data['Label']]\n",
    "    ],\n",
    "    axis=0,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "mismatch_data.to_csv(os.path.join(save_path,'logs/mismatch_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = {**hyper_params, **f1_scores}\n",
    "run.config.update(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = os.path.join(save_path,'logs')\n",
    "log_artifact = wandb.Artifact(\"fraud-detector-logs\", type=\"logs\")\n",
    "log_artifact.add_dir(logs_path)\n",
    "run.use_artifact(log_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(os.path.join(save_path,'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(save_path, 'model')\n",
    "model_artifact = wandb.Artifact(\"fraud-detector-model\", type=\"model\")\n",
    "model_artifact.add_dir(model_path)\n",
    "run.use_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
