{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /common/home/ps1279/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from detector.data_loader import LoadEnronData, LoadPhishingData, LoadSocEnggData\n",
    "from detector.labeler import EnronLabeler, MismatchLabeler\n",
    "from ethics.differential_privacy import RandomForestPrivacyModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from detector.preprocessor import Preprocessor\n",
    "from utils.util_modeler import evaluate_and_log, get_f1_score, Augmentor\n",
    "\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from diffprivlib.models.logistic_regression import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init wandb for model tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/06/2023 11:17:49:ERROR:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madvaithrao\u001b[0m (\u001b[33mregressors\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /common/home/ps1279/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/common/home/ps1279/Fraud-Detector/wandb/run-20231206_111750-kkacars7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/regressors/Fraud-Detector/runs/kkacars7' target=\"_blank\">frosty-salad-118</a></strong> to <a href='https://wandb.ai/regressors/Fraud-Detector' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/regressors/Fraud-Detector' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/regressors/Fraud-Detector/runs/kkacars7' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector/runs/kkacars7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandbdict = {\n",
    "    'key': os.getenv('WANDB_API_KEY'),\n",
    "    'entity': os.getenv('WANDB_ENTITY'),\n",
    "    'project': os.getenv('WANDB_PROJECT'),\n",
    "}\n",
    "wandb.login(key=wandbdict['key'])\n",
    "run = wandb.init(project=wandbdict['project'], entity=wandbdict['entity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data file is too large to upload to github, so you will need to run from https://github.com/advaithsrao/Fraud-Detector/wiki/Load-Preprocessed-and-Labeled-Data#The data file is too large to upload to github, \n",
    "#so you will need to run data loading from https://github.com/advaithsrao/Fraud-Detector/wiki/Load-Preprocessed-and-Labeled-Data \n",
    "#and save it to <repo>/data/fraud_detector_data.csv\n",
    "data = pd.read_csv('./data/fraud_detector_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data.Split == 'Train']\n",
    "sanity_data = data[data.Split == 'Sanity']\n",
    "gold_fraud_data = data[data.Split == 'Gold Fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentor = Augmentor()\n",
    "\n",
    "train_body, train_labels = augmentor(\n",
    "    train_data['Body'].tolist(),\n",
    "    train_data['Label'].tolist(),\n",
    "    aug_label=1,\n",
    "    num_aug_per_label_1=9,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data = pd.DataFrame(\n",
    "    {\n",
    "        'Body': train_body,\n",
    "        'Label': train_labels\n",
    "    }\n",
    ")\n",
    "\n",
    "train_data.drop_duplicates(subset=['Body'], inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_csv('./data/augmented_train_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('./data/augmented_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = train_data['Body'].tolist()\n",
    "label = train_data['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train, body_val, label_train, label_val = train_test_split(body, label, test_size=0.2, random_state=42, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:239: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:239: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:239: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:239: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:419: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n",
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:239: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== \n",
      " Best Model for Epsilon = 20 with Validation F1 Score = 0.9192553965725826 \n",
      " ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:239: PrivacyLeakWarning:\n",
      "\n",
      "Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Training Done ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/ps1279/.cache/pypoetry/virtualenvs/ethical-fraud-detector-qnRNkJHZ-py3.10/lib/python3.10/site-packages/diffprivlib/models/logistic_regression.py:419: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils.util_modeler import Word2VecEmbedder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = Word2VecEmbedder()\n",
    "# Call your code that produces output\n",
    "# model.train(train_data['Body'], train_data['Label'], wandb = run)\n",
    "\n",
    "epsilons = [1e-8, 1e-2, 1, 7.5, 20]\n",
    "accuracies = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    model = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', LogisticRegression(n_jobs=-1, epsilon = eps))\n",
    "    ])\n",
    "\n",
    "    model.fit(body_train, label_train)\n",
    "\n",
    "    accuracy = get_f1_score(label_val, model.predict(body_val), average = 'macro')\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "plt.plot(epsilons, accuracies, marker='o')\n",
    "plt.xscale('log')  # Use a logarithmic scale for better visibility\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Epsilon')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"lr_dp_accuracy_vs_epsilon_plot.png\")\n",
    "\n",
    "# Log the plot to wandb\n",
    "wandb.log({\"Accuracy vs Epsilon\": plt})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'{\"=\"*20} \\n Best Model for Epsilon = {epsilons[np.argmax(accuracies)]} with Validation F1 Score = {np.max(accuracies)} \\n {\"=\"*20}')\n",
    "\n",
    "#Fit model with best epsilon\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', LogisticRegression(n_jobs=-1, epsilon = epsilons[np.argmax(accuracies)]))\n",
    "])\n",
    "\n",
    "model.fit(body_train, label_train)\n",
    " \n",
    "print(f'{\"=\"*20} Training Done {\"=\"*20}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {}\n",
    "os.makedirs('/common/home/ps1279/models/rf_diff_privacy/2023-12-05/rf_diff_privacy/logs', exist_ok=True)\n",
    "save_path='/common/home/ps1279/models/rf_diff_privacy/2023-12-05/rf_diff_privacy/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on all datasets and generate logs + mismatch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Prediction'] = model.predict(train_data['Body'])\n",
    "\n",
    "preds = train_data['Prediction'].tolist()\n",
    "\n",
    "evaluate_and_log(x=train_data['Body'].tolist(), y_true=train_data['Label'].tolist(), y_pred=train_data['Prediction'].tolist(), filename=os.path.join(save_path,'logs/train.log'), experiment=run)#, id = train_data['Mail-ID'].tolist())\n",
    "f1_scores['train'] = get_f1_score(y_true=train_data['Label'].tolist(), y_pred=train_data['Prediction'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 103105 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 123159 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 278404 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 1401178 bytes\n"
     ]
    }
   ],
   "source": [
    "sanity_data['Prediction'] = model.predict(sanity_data['Body'])\n",
    "\n",
    "evaluate_and_log(x=sanity_data['Body'].tolist(), y_true=sanity_data['Label'].tolist(), y_pred=sanity_data['Prediction'].tolist(), filename=os.path.join(save_path,'logs/sanity.log'), experiment=run)#, id = sanity_data['Mail-ID'].tolist())\n",
    "f1_scores['sanity'] = get_f1_score(y_true=sanity_data['Label'].tolist(), y_pred=sanity_data['Prediction'].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fraud_data['Prediction'] = model.predict(gold_fraud_data['Body'])\n",
    "\n",
    "evaluate_and_log(x=gold_fraud_data['Body'].tolist(), y_true=gold_fraud_data['Label'].tolist(), y_pred=gold_fraud_data['Prediction'].tolist(), filename=os.path.join(save_path,'logs/gold_fraud.log'), experiment=run)#, id = gold_fraud_data['Mail-ID'].tolist())\n",
    "f1_scores['gold_fraud'] = get_f1_score(y_true=gold_fraud_data['Label'].tolist(), y_pred=gold_fraud_data['Prediction'].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9180848923103692,\n",
       " 'sanity': 0.9737548053931238,\n",
       " 'gold_fraud': 0.9604989604989606}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save mismatch data into a csv file\n",
    "mismatch_data = pd.concat(\n",
    "    [\n",
    "        train_data[train_data['Prediction'] != train_data['Label']],\n",
    "        sanity_data[sanity_data['Prediction'] != sanity_data['Label']],\n",
    "        gold_fraud_data[gold_fraud_data['Prediction'] != gold_fraud_data['Label']]\n",
    "    ],\n",
    "    axis=0,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "mismatch_data.to_csv(os.path.join(save_path,'logs/mismatch_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = {**hyper_params, **f1_scores}\n",
    "run.config.update(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/common/home/ps1279/models/rf_diff_privacy/2023-12-05/rf_diff_privacy/logs)... Done. 0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact QXJ0aWZhY3Q6NjU5MjgwMDc5>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_path = os.path.join(save_path,'logs')\n",
    "log_artifact = wandb.Artifact(\"fraud-detector-logs\", type=\"logs\")\n",
    "log_artifact.add_dir(logs_path)\n",
    "run.use_artifact(log_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.sklearn import save_model\n",
    "save_model(model, os.path.join(save_path,'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/common/home/ps1279/models/rf_diff_privacy/2023-12-05/rf_diff_privacy/model)... Done. 12.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact QXJ0aWZhY3Q6NjU5Mjg0NzIz>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(save_path, 'model')\n",
    "model_artifact = wandb.Artifact(\"fraud-detector-model\", type=\"model\")\n",
    "model_artifact.add_dir(model_path)\n",
    "run.use_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /common/home/ps1279/models/rf_diff_privacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a21828e7304a538e81ffeba839b337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3669.621 MB of 3669.621 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-salad-118</strong> at: <a href='https://wandb.ai/regressors/Fraud-Detector/runs/kkacars7' target=\"_blank\">https://wandb.ai/regressors/Fraud-Detector/runs/kkacars7</a><br/>Synced 6 W&B file(s), 4 media file(s), 12 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231206_111750-kkacars7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
